{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras, cv2, random, os, csv, json\n",
    "from pathlib import Path\n",
    "from os import listdir\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras import layers\n",
    "from keras.layers import GlobalAveragePooling2D, Conv2D, Conv3D, MaxPooling2D, MaxPooling3D, Dropout, Flatten\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import MaxPooling3D\n",
    "from keras.layers import AveragePooling3D\n",
    "from keras.layers import GlobalAveragePooling3D\n",
    "import time\n",
    "from keras.utils import layer_utils\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_list_csv(num_classes):\n",
    "    csv_dir = \"/home/t-ziwang/action_classification/five-video-classification-methods/data/data_file.csv\"\n",
    "    with open(csv_dir, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        csv_list = np.array(list(reader))\n",
    "    partition = {}\n",
    "    label = {}\n",
    "    t_num = 0\n",
    "    v_num = 0\n",
    "    class_no = 0\n",
    "    class_list = np.unique(csv_list[:,1])\n",
    "    np.random.shuffle(class_list)\n",
    "    for iclass in class_list:\n",
    "        if class_no < num_classes:\n",
    "            label[iclass] = class_no\n",
    "            class_no = class_no + 1\n",
    "    for line in range(np.size(csv_list,0)):\n",
    "        if csv_list[line,1] in label.keys():\n",
    "            if csv_list[line,0] == \"train\":\n",
    "                if random.random() <= 0.8:\n",
    "                    # train\n",
    "                    if t_num == 0:\n",
    "                        t_list = csv_list[line,-3:]\n",
    "                        t_num = t_num + 1\n",
    "                    else:\n",
    "                        t_list = np.vstack((t_list, csv_list[line,-3:]))\n",
    "                else:\n",
    "                    # valid\n",
    "                    if v_num == 0:\n",
    "                        v_list = csv_list[line,-3:]\n",
    "                        v_num = v_num + 1\n",
    "                    else:\n",
    "                        v_list = np.vstack((v_list, csv_list[line,-3:]))\n",
    "    partition['train'] = t_list\n",
    "    partition['validation'] = v_list\n",
    "    return partition, label\n",
    "\n",
    "def partition_per_frame(partlist, clip_length = 15):\n",
    "    for i, item in enumerate(partlist):\n",
    "        if i == 0:\n",
    "            out_list = np.array([[item[0], item[1], idx + 1] for idx in range(int(item[2]) - clip_length - 1)])\n",
    "        else:\n",
    "            out_list = np.concatenate((out_list, np.array([[item[0], item[1], idx + 1] for idx in range(int(item[2]) - clip_length - 1)])), axis = 0)\n",
    "            \n",
    "    return out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class precomp():\n",
    "    def __init__(self, trs_res):\n",
    "        self.row, self.col = trs_res\n",
    "        \n",
    "        dn = 1/float(np.min((self.col, self.row)))\n",
    "        log_rho_axis = np.linspace(np.log(dn), 0, self.col)\n",
    "        theta_axis = np.linspace(0, np.pi*(1-dn), self.row)\n",
    "        x0 = self.col/2.0\n",
    "        y0 = self.row/2.0\n",
    "        rmax = np.sqrt(x0**2 + y0**2)\n",
    "        lp_table_x = np.empty((self.row, self.col))\n",
    "        lp_table_y = np.empty((self.row, self.col))\n",
    "        self.mask = np.ones((self.row, self.col))\n",
    "        for ii in range(self.row):\n",
    "            for jj in range(self.col):\n",
    "                rho = np.exp(log_rho_axis[jj])\n",
    "                theta = theta_axis[-ii-1]\n",
    "                xx = x0 + rho * np.cos(theta) * rmax\n",
    "                yy = y0 - rho * np.sin(theta) * rmax\n",
    "                if xx < 0 or xx > (self.col - 1) or yy < 0 or yy > (self.row - 1):\n",
    "                    self.mask[ii,jj] = 0\n",
    "                lp_table_x[ii,jj] = xx\n",
    "                lp_table_y[ii,jj] = yy\n",
    "        lp_table_x = lp_table_x.flatten()\n",
    "        lp_table_y = lp_table_y.flatten()\n",
    "        cleft = np.floor(lp_table_x).astype(int)\n",
    "        cright = cleft + 1\n",
    "        ax = lp_table_x - cleft\n",
    "        cup = np.floor(lp_table_y).astype(int)\n",
    "        cdown = cup + 1\n",
    "        ay = lp_table_y - cup\n",
    "        self.iul = cup*self.col + cleft\n",
    "        self.iur = cup*self.col + cright\n",
    "        self.idl = cdown*self.col + cleft\n",
    "        self.idr = cdown*self.col + cright\n",
    "        self.aul = np.multiply((1-ax), (1-ay))\n",
    "        self.aur = np.multiply(ax, (1-ay))\n",
    "        self.adl = np.multiply((1-ax), ay)\n",
    "        self.adr = np.multiply(ax, ay)\n",
    "        self.mask = self.mask.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, labels, \n",
    "                 work_dir=\"/home/t-ziwang/action_classification/five-video-classification-methods/data/train/\", \n",
    "                 batch_size=32, dim=(224,224), n_channels=1, op_res = (256, 256), skip = 1, ms_skip = None,\n",
    "                 n_classes=10, mode = 'vid', trs_res = (256, 256), trs_precomp = None,\n",
    "                 psf = None, stack = False, shuffle=True, verbose = 0):\n",
    "        'Initialization'\n",
    "        self.work_dir = work_dir\n",
    "        self.dim = dim\n",
    "        self.dh, self.dw = self.dim\n",
    "        self.h1 = self.dh // 2\n",
    "        self.w1 = self.dw // 2\n",
    "        self.h2 = self.dh - self.h1\n",
    "        self.w2 = self.dw - self.h2\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.mode = mode\n",
    "        self.n_channels = n_channels\n",
    "        self.skip = skip\n",
    "        if self.mode == \"vid-trs\" or self.mode == \"ca-trs\" or self.mode == \"ms-trs\":\n",
    "            if self.mode == \"ms-trs\":\n",
    "                self.row, self.col = trs_res\n",
    "                self.n_channels = 13\n",
    "                self.ms_skip = ms_skip\n",
    "                self.frame_idx = self.get_frame_idx()\n",
    "                self.dim3 = self.get_dim3()\n",
    "            else:\n",
    "                self.n_channels = self.n_channels + 1\n",
    "                self.row, self.col = trs_res\n",
    "            if trs_precomp == None:\n",
    "                self.trs_precomp_flag = 0\n",
    "                self.precompute_lp = 0\n",
    "            else:\n",
    "                self.trs_precomp_flag = 1\n",
    "                self.precompute_lp = 1\n",
    "                self.trs_precomp = trs_precomp\n",
    "        if self.mode == \"ca\" or self.mode == \"ca-trs\":\n",
    "            self.psf = psf\n",
    "            self.psf_res = (np.size(self.psf, 0), np.size(self.psf, 1))\n",
    "            self.psf_fft = np.fft.fft2(self.psf)\n",
    "        self.op_res = op_res\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        self.stack = stack\n",
    "        self.shuffle = shuffle\n",
    "        self.verbose = verbose\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(0.3*np.size(self.list_IDs, 0) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k,:] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(np.size(self.list_IDs,0))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "    def read_image_sequence(self, vid_dir, img_basename, start_idx):\n",
    "        vid = [img_to_array(load_img(os.path.join(vid_dir, img_basename + '%0*d' % (4, start_idx + self.skip * iframe) + \".jpg\"), target_size = self.op_res, grayscale = True)) for iframe in range(self.n_channels)]\n",
    "        return np.squeeze((np.array(vid) / 255.).astype(np.float32))\n",
    "    \n",
    "    def get_frame_idx(self):\n",
    "        return np.array([np.arange(0, self.n_channels, iskip) for iskip in self.ms_skip])\n",
    "    \n",
    "    def get_dim3(self):\n",
    "        dim3 = 0\n",
    "        for i in self.ms_skip:\n",
    "            dim3 = dim3 + len(np.arange(0, self.n_channels, i)) - 1\n",
    "        return dim3*2\n",
    "            \n",
    "    def norm_max(self, img):\n",
    "        return img/np.amax(img)\n",
    "    \n",
    "    def crop_video(self, vid):\n",
    "        H, W = self.op_res\n",
    "        h = random.randint(0, H - self.dh - 1)\n",
    "        w = random.randint(0, W - self.dw - 1)\n",
    "        return vid[:, h:(h + self.dh), w:(w + self.dw)]\n",
    "    \n",
    "    def image_downsize(self, img):\n",
    "        return resize(img, self.dim, mode = 'reflect', anti_aliasing=True)\n",
    "        \n",
    "    def video2ca(self, vid):\n",
    "        return np.array([self.image_downsize(np.absolute(np.fft.ifft2(np.multiply(np.fft.fft2(resize(vid[i,:,:], self.psf_res, mode = 'reflect', anti_aliasing=True)), self.psf_fft)))) for i in range(np.size(vid,0))])\n",
    "    \n",
    "    def crop_resize_video(self, vid):\n",
    "        H, W = self.op_res\n",
    "        h = random.randint(0, H - self.dh - 1)\n",
    "        w = random.randint(0, W - self.dw - 1)\n",
    "        return np.array([resize(vid[i, h:(h+self.dh), w:(w+self.dw)], (self.row, self.col), mode = 'reflect', anti_aliasing=True) for i in range(np.size(vid, 0))])\n",
    "    \n",
    "    def crop_center_img(self, img):\n",
    "        Hc = self.row // 2\n",
    "        Wc = self.col // 2\n",
    "        return img[(Hc - self.h1): (Hc + self.h2), (Wc - self.w1): (Wc + self.w2)]\n",
    "    \n",
    "    def cropy_resizex_img(self, img):\n",
    "        Hc = self.row // 2\n",
    "        Wc = self.col // 2\n",
    "        return resize(img[(Hc - self.h1): (Hc + self.h2), :] , (self.dh, self.dw), mode = 'reflect', anti_aliasing = True)\n",
    "    \n",
    "    def phase_corr(self,img1,img2):\n",
    "        self.img1_fft_t = np.fft.fftshift(np.fft.fft2(img1))\n",
    "        self.img2_fft_t = np.fft.fftshift(np.fft.fft2(img2))\n",
    "        temp_dot = np.multiply(self.img1_fft_t, np.conj(self.img2_fft_t))\n",
    "        cps = temp_dot/(np.absolute(temp_dot)+np.finfo(float).eps)\n",
    "        cps_ifft = np.nan_to_num(np.absolute(np.fft.fftshift(np.fft.ifft2(cps))))\n",
    "        return cps_ifft\n",
    "    \n",
    "    def log_polar_precomp(self, img):\n",
    "        img_flat = img.flatten()\n",
    "        if self.precompute_lp == 0:\n",
    "            dn = 1/float(self.col)\n",
    "            log_rho_axis = np.linspace(np.log(dn), 0, self.col)\n",
    "            theta_axis = np.linspace(0, np.pi*(1-dn), self.row)\n",
    "            x0 = self.col/2.0\n",
    "            y0 = self.row/2.0\n",
    "            rmax = np.sqrt(x0**2 + y0**2)\n",
    "            lp_table_x = np.empty((self.row, self.col))\n",
    "            lp_table_y = np.empty((self.row, self.col))\n",
    "            self.mask = np.ones((self.row, self.col))\n",
    "            for ii in range(self.row):\n",
    "                for jj in range(self.col):\n",
    "                    rho = np.exp(log_rho_axis[jj])\n",
    "                    theta = theta_axis[-ii-1]\n",
    "                    xx = x0 + rho * np.cos(theta) * rmax\n",
    "                    yy = y0 - rho * np.sin(theta) * rmax\n",
    "                    if xx < 0 or xx > (self.col - 1) or yy < 0 or yy > (self.row - 1):\n",
    "                        self.mask[ii,jj] = 0\n",
    "                    lp_table_x[ii,jj] = xx\n",
    "                    lp_table_y[ii,jj] = yy\n",
    "            lp_table_x = lp_table_x.flatten()\n",
    "            lp_table_y = lp_table_y.flatten()\n",
    "            cleft = np.floor(lp_table_x).astype(int)\n",
    "            cright = cleft + 1\n",
    "            ax = lp_table_x - cleft\n",
    "            cup = np.floor(lp_table_y).astype(int)\n",
    "            cdown = cup + 1\n",
    "            ay = lp_table_y - cup\n",
    "            self.iul = cup*self.col + cleft\n",
    "            self.iur = cup*self.col + cright\n",
    "            self.idl = cdown*self.col + cleft\n",
    "            self.idr = cdown*self.col + cright\n",
    "            self.aul = np.multiply((1-ax), (1-ay))\n",
    "            self.aur = np.multiply(ax, (1-ay))\n",
    "            self.adl = np.multiply((1-ax), ay)\n",
    "            self.adr = np.multiply(ax, ay)\n",
    "            self.mask = self.mask.flatten()\n",
    "            self.precompute_lp = 1\n",
    "        if self.trs_precomp_flag == 0:\n",
    "            canvas = np.multiply(self.mask, np.multiply(img_flat[self.iul], self.aul) + np.multiply(img_flat[self.iur], self.aur) + np.multiply(img_flat[self.idl], self.adl) + np.multiply(img_flat[self.idr], self.adr))    \n",
    "        else:\n",
    "            canvas = np.multiply(self.trs_precomp.mask, np.multiply(img_flat[self.trs_precomp.iul], self.trs_precomp.aul) + np.multiply(img_flat[self.trs_precomp.iur], self.trs_precomp.aur) + np.multiply(img_flat[self.trs_precomp.idl], self.trs_precomp.adl) + np.multiply(img_flat[self.trs_precomp.idr], self.trs_precomp.adr))    \n",
    "        return canvas.reshape(self.row, self.col)\n",
    "    \n",
    "    def TRSmaps(self,img1,img2):\n",
    "        tmap = self.phase_corr(img1,img2)\n",
    "        img1_lp = self.log_polar_precomp(np.absolute(self.img1_fft_t))\n",
    "        img2_lp = self.log_polar_precomp(np.absolute(self.img2_fft_t))\n",
    "        rsmap = self.phase_corr(img1_lp,img2_lp)\n",
    "        return tmap, rsmap\n",
    "    \n",
    "    def trs_crop(self, img1, img2):\n",
    "        tmap, rsmap = self.TRSmaps(img1, img2)\n",
    "        return np.concatenate((np.expand_dims(self.crop_center_img(tmap), axis = 0), np.expand_dims(self.cropy_resizex_img(rsmap), axis = 0)), axis = 0)\n",
    "    \n",
    "    def ms_trs(self, vid, scale):\n",
    "        [[self.trs_crop] for iscale in scales]\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "        if self.mode == 'vid' or self.mode == 'ca':\n",
    "            X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        elif self.mode == 'ms-trs':\n",
    "            X = np.empty((self.batch_size, *self.dim, self.dim3))\n",
    "        elif self.stack == True:\n",
    "            X = np.empty((self.batch_size, *self.dim, (self.n_channels-1)*2))\n",
    "        else:\n",
    "            X = np.empty((self.batch_size, 2, *self.dim, (self.n_channels-1)))\n",
    "        # Generate data\n",
    "        time_prep_samp = time.time()\n",
    "        if self.verbose == 1:\n",
    "            print(\"Preparing samples...\", self.mode)\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            if self.verbose == 1:\n",
    "                print(\"i\", i, \"ID\", ID)\n",
    "            if self.mode == 'vid':\n",
    "                # Store sample\n",
    "#                 rand_start_idx = random.randint(1, int(ID[2]) - self.n_channels * self.skip - 1)\n",
    "#                 time_read = time.time()\n",
    "#                 vid = self.read_image_sequence(os.path.join(self.work_dir, ID[0]),ID[1] + \"-\", rand_start_idx)\n",
    "#                 time_crop_trans = time.time()\n",
    "                vid = self.read_image_sequence(os.path.join(self.work_dir, ID[0]),ID[1] + \"-\", int(ID[2]))\n",
    "                X[i,] = np.transpose(self.crop_video(vid), (1,2,0))\n",
    "                # Store class\n",
    "                y[i] = self.labels[ID[0]]\n",
    "            elif self.mode == 'vid-trs':\n",
    "#                 rand_start_idx = random.randint(1, int(ID[2]) - self.n_channels * self.skip - 1)\n",
    "#                 vid = self.crop_resize_video(self.read_image_sequence(os.path.join(self.work_dir, ID[0]),ID[1] + \"-\", rand_start_idx))\n",
    "                vid = self.crop_resize_video(self.read_image_sequence(os.path.join(self.work_dir, ID[0]),ID[1] + \"-\", int(ID[2])))\n",
    "\n",
    "                if self.stack == True:\n",
    "                    X[i,] = np.transpose(np.resize(np.array([self.trs_crop(vid[j,:,:], vid[j+1,:,:]) for j in range(self.n_channels - 1)]), ((self.n_channels-1)*2, *self.dim)), (1,2,0))\n",
    "                else:\n",
    "                    X[i,] = np.transpose(np.array([self.trs_crop(vid[j,:,:], vid[j+1,:,:]) for j in range(self.n_channels - 1)]), (1,2,3,0))\n",
    "                y[i] = self.labels[ID[0]]\n",
    "            elif self.mode == 'ms-trs':\n",
    "#                 rand_start_idx = random.randint(1, int(ID[2]) - self.n_channels - 1)\n",
    "#                 vid = self.crop_resize_video(self.read_image_sequence(os.path.join(self.work_dir, ID[0]),ID[1] + \"-\", rand_start_idx))\n",
    "                vid = self.crop_resize_video(self.read_image_sequence(os.path.join(self.work_dir, ID[0]),ID[1] + \"-\", int(ID[2])))\n",
    "                for iskip in range(len(self.ms_skip)):\n",
    "                    temp = np.transpose(np.reshape(np.array([self.trs_crop(vid[self.frame_idx[iskip][j],:,:], vid[self.frame_idx[iskip][j+1],:,:]) \n",
    "                                                             for j in range(len(self.frame_idx[iskip]) - 1)]), (2*(len(self.frame_idx[iskip])-1),*self.dim)), (1,2,0))\n",
    "                    if iskip == 0:\n",
    "                        ms_trs = temp\n",
    "                    else:\n",
    "                        ms_trs = np.concatenate((ms_trs, temp), axis = 2)\n",
    "                X[i,] = ms_trs\n",
    "                y[i] = self.labels[ID[0]]\n",
    "#                     print(temp.shape)\n",
    "#                     plt.figure()\n",
    "#                     plt.subplot(121)\n",
    "#                     plt.imshow(temp[:,:,1]**0.1)\n",
    "#                     plt.subplot(122)\n",
    "#                     plt.imshow(temp[:,:,2]**0.1)\n",
    "#                 break\n",
    "#                 \n",
    "#                 \n",
    "#                 np.transpose(np.resize(np.array([self.trs_crop(vid[j,:,:], vid[j+1,:,:]) for j in range(self.n_channels - 1)]), ((self.n_channels-1)*2, *self.dim)), (1,2,0))\n",
    "            elif self.mode == 'ca':\n",
    "                rand_start_idx = random.randint(1, int(ID[2]) - self.n_channels * self.skip - 1)\n",
    "                vid = self.read_image_sequence(os.path.join(self.work_dir, ID[0]),ID[1] + \"-\", rand_start_idx)\n",
    "#                 plt.figure()\n",
    "#                 plt.imshow(vid[0,:,:])\n",
    "#                 temp = np.transpose(self.video2ca(self.crop_video(vid)), (1,2,0))\n",
    "                \n",
    "#                 plt.figure()\n",
    "#                 plt.imshow(temp[:,:,0])\n",
    "                X[i,] = np.transpose(self.video2ca(self.crop_video(vid)), (1,2,0))\n",
    "                y[i] = self.labels[ID[0]]\n",
    "        if self.verbose == 1:\n",
    "            print(\"Finished preparing samples! size:\", np.array(X).shape, \"time taken:\", time.time() - time_prep_samp)\n",
    "        return np.array(X), keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
    "\n",
    "def norm_sum(img):\n",
    "        return img/np.sum(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_2d(num_classes, input_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), strides = (1, 1), padding = \"same\", input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), strides = (1, 1), padding = \"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
    "    \n",
    "    for i in range(2):\n",
    "        model.add(Conv2D(128, (3, 3), strides = (1, 1), padding = \"same\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
    "    \n",
    "    for i in range(3):\n",
    "        model.add(Conv2D(256, (3, 3), strides = (1, 1), padding = \"same\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
    "    \n",
    "    for i in range(3):\n",
    "        model.add(Conv2D(512, (3, 3), strides = (1, 1), padding = \"same\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
    "       \n",
    "    for i in range(3):\n",
    "        model.add(Conv2D(512, (3, 3), strides = (1, 1), padding = \"same\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
    "    \n",
    "    model.add(Flatten())   \n",
    "    \n",
    "    for i in range(2):\n",
    "        model.add(Dense(4096, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "     \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training video # 363\n",
      "validation video # 88\n",
      "{'Fencing': 0, 'Shotput': 1, 'BabyCrawling': 2, 'BaseballPitch': 3, 'TaiChi': 4}\n"
     ]
    }
   ],
   "source": [
    "num_classes = 5\n",
    "# partition, labels = partition_list_csv(num_classes)\n",
    "save_dir = \"/home/t-ziwang/action_classification/winston_action_classification/\"\n",
    "# np.save(save_dir + \"ucf-partition-labels-\" + \"%03dc.npy\" % num_classes, (partition, labels))\n",
    "partition, labels = np.load(save_dir + \"ucf-partition-labels-\" + \"%03dc.npy\" % num_classes)\n",
    "print(\"training video #\", np.size(partition['train'], 0))\n",
    "print(\"validation video #\", np.size(partition['validation'], 0))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training video # 41841\n",
      "[['Shotput' 'v_Shotput_g16_c05' '1']\n",
      " ['Shotput' 'v_Shotput_g16_c05' '2']\n",
      " ['Shotput' 'v_Shotput_g16_c05' '3']\n",
      " ...\n",
      " ['BabyCrawling' 'v_BabyCrawling_g16_c06' '174']\n",
      " ['BabyCrawling' 'v_BabyCrawling_g16_c06' '175']\n",
      " ['BabyCrawling' 'v_BabyCrawling_g16_c06' '176']]\n",
      "validation video # 9759\n",
      "{'Fencing': 0, 'Shotput': 1, 'BabyCrawling': 2, 'BaseballPitch': 3, 'TaiChi': 4}\n"
     ]
    }
   ],
   "source": [
    "partition['train'] = partition_per_frame(partition['train'], clip_length = 15)\n",
    "partition['validation'] = partition_per_frame(partition['validation'], clip_length = 15)\n",
    "print(\"training video #\", np.size(partition['train'], 0))\n",
    "print(partition['train'])\n",
    "print(\"validation video #\", np.size(partition['validation'], 0))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trs_res = (512, 512)\n",
    "trs_precomp = precomp(trs_res)\n",
    "#psf = norm_sum(imread(\"/home/t-ziwang/action_classification/MLS_psf/mask-MLS-256-1x-0s-1r-(0,0)-1.0-synth.png\", as_gray = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = 13\n",
    "train_bsz = 32\n",
    "valid_bsz = 32\n",
    "# Parameters\n",
    "train_params = {'work_dir': \"/home/t-ziwang/action_classification/five-video-classification-methods/data/train/\",\n",
    "          'dim': (224,224),\n",
    "          'batch_size': train_bsz,\n",
    "          'n_classes': num_classes,\n",
    "          'n_channels': num_channels,\n",
    "          'op_res': (240, 320), # operating resolution\n",
    "          'trs_res': trs_res, # resolution for computing trs\n",
    "          'trs_precomp': trs_precomp, # precomputed trs log-polar class object\n",
    "          'skip': 1, # skip frames, 1 -- no skip\n",
    "          'ms_skip': [2,3,4,6], # skip frames, 1 -- no skip\n",
    "          'mode': 'vid', # \"vid\", \"vid-trs\", \"ca\", \"ca-trs\"\n",
    "          'psf': None, \n",
    "          'stack': True, # for trs generation, if true, output stacked trs, otherwise output two-stream tuple\n",
    "          'shuffle': True,\n",
    "          'verbose': 0}\n",
    "\n",
    "val_params = train_params.copy()\n",
    "val_params['batch_size'] = valid_bsz\n",
    "# Generators\n",
    "# training_generator = DataGenerator(partition['train'], labels, **train_params)\n",
    "# t_mstrs = time.time()\n",
    "# X, y = training_generator.__getitem__(0)\n",
    "# print(X.shape)\n",
    "# print(time.time() - t_mstrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "392/392 [==============================] - 27035s 69s/step - loss: 1.7886 - acc: 0.4281 - val_loss: 1.1758 - val_acc: 0.5532\n",
      "Epoch 2/10\n",
      "392/392 [==============================] - 26226s 67s/step - loss: 1.0854 - acc: 0.5977 - val_loss: 2.8672 - val_acc: 0.3080\n",
      "Epoch 3/10\n",
      "392/392 [==============================] - 25022s 64s/step - loss: 0.9472 - acc: 0.6544 - val_loss: 1.9949 - val_acc: 0.2229\n",
      "Epoch 4/10\n",
      "137/392 [=========>....................] - ETA: 3:36:44 - loss: 0.8529 - acc: 0.6880"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "verbose = 1\n",
    "mode_list = ['ms-trs']\n",
    "history = {}\n",
    "for imode in mode_list:\n",
    "    train_params['mode'] = imode\n",
    "    val_params['mode'] = imode\n",
    "    if imode == 'vid' or imode == 'ca':\n",
    "        train_params['n_channels'] = num_channels\n",
    "        val_params['n_channels'] = num_channels\n",
    "        model = conv_2d(train_params['n_classes'], (*train_params['dim'], train_params['n_channels']))\n",
    "    elif imode == 'ms-trs':\n",
    "        model = conv_2d(train_params['n_classes'], (*train_params['dim'], 30))\n",
    "    else:\n",
    "        train_params['n_channels'] = num_channels - 1\n",
    "        val_params['n_channels'] = num_channels - 1\n",
    "        model = conv_2d(train_params['n_classes'], (*train_params['dim'], train_params['n_channels']*2))\n",
    "    training_generator = DataGenerator(partition['train'], labels, **train_params)\n",
    "    validation_generator = DataGenerator(partition['validation'], labels, **val_params)\n",
    "    adam = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0.0, amsgrad=False)\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history[imode] = model.fit_generator(generator=training_generator,\n",
    "                        validation_data=validation_generator,\n",
    "                        use_multiprocessing=True, epochs=epochs, verbose = verbose,\n",
    "                        workers=6, initial_epoch = 0)\n",
    "    model.save(save_dir + train_params['mode'] + \"-%03dcl\" % num_classes + \"-%02dch\" % num_channels + \"-%03dtrsres\" % trs_res[0] + \"-%03dep-model.h5\" % epochs)\n",
    "    history_dict = history[imode].history\n",
    "    json.dump(history_dict, open(save_dir + train_params['mode'] + \"-%03dcl\" % num_classes + \"-%02dch\" % num_channels + \"-%03dtrsres\" % trs_res[0] + \"-%03dep-history.json\" % epochs, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(save_dir + train_params['mode'] + \"-%03dcl\" % num_classes + \"-%02dch\" % num_channels + \"-%03dtrsres\" % trs_res[0] + \"-%03dep-model.h5\" % epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
